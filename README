PROJECT: LearnLanguages
AUTHOR: William Raiford (bill.mybiz@gmail.com)


VISION: I want to learn languages quickly, efficiently, and organically to maximize retention and minimize time investment.  I also want a specific goal, currently 2000 words, and I want to see just _one_ real number metric to see my progress towards that goal in any particular language.  I want to be able to write in a bunch of text, have the app persist that text, and allow quick user actions to create translations in multiple languages to grow just a database of text and text relationships.  Eventually, I want to include item scheduling using a neural net to maximize retention and minimize repetitions necessary for learning.

SUMMARY: To start with, the problem becomes three-fold:

1. Input text data ("Phrase"), associated with a Language.
2. Create text relationships (translations) among those text data.
3. Execute metrics on user knowledge of those text relationships, or IOW test for knowledge to assess progress.

NOTES ON BUILDING/RUNNING:
-Be sure to manually set the IISHost project as the StartUp Project.
-To switch between the Mock and Ef data providers: IISHost project -> Web.config -> <appsettings> -> key="DalManagerType".
-To switch between Silverlight Unit Testing UI and the actual Silverlight app UI: IISHost project -> Project Properties -> Web tab -> Specific Page(.TestsTestPage is the UnitTesting page right now - bad naming sorry).
-I usually work in a feature branch and then merge it back into master, so for most up-to-date code, check out the [feature] branch.

JOURNAL:
01/03/12
I've fleshed out PhraseEdit and LanguageEdit somewhat, but I'm still working on the asynchronization of my WCF calls.  Basic WCF service runs using BasicHttpBinding (because of SL requirements, it can't use WsHttpBinding).  

01/04/12
Restructured architecture to better reflect my increasing knowledge of setting up the data portal properly.  Instead of trying to host my own WCF service, I have created a IIS web page that exposes the Csla data portal service, so I can program a more proper Csla-way.

01/10/12
I've gotten tests passing for basic plumbing for the most basic structure.  I have a PhraseEdit and a LanguageEdit, and I have plumbing to CRUD those objects using EF.  Now, I am going to be focusing on authentication.

01/19/12
I've integrated authentication into the main LearnLanguages project.  This includes the software architecture with PhraseEdit and LanguageEdit, as well as the Ef database structure/model, including FK associations. I also have some basic pub-sub navigation in place as well, handled by Caliburn event aggregator.  I have the Ef database being deleted and seeded, controlled by a setting in EfResources.  Currently all tests passing for basic CRUD functionality in LanguageTests and PhraseTests, and the SecurityTests are passing as well.

01/24/12
Basic functionality is working now.  I can login, add phrases, view phrases, edit phrases, delete phrases.  None of it is super evolved, ie you can't do everything very fast, and it is not efficient, but it is usable with my vision of how it is intended to be used.  I won't be adding a bunch of little words, I will be adding long texts, ie groups of words.  Some may be song lyrics, or poems, or whatever.  Then, it will be part of the process of "learning" these phrases that will break these phrases down into different atomic units.  

01/29/12
I've integrated TranslationEdit functionality into both Mock and Ef Data Providers now.  A translation is a collection of phrases, requiring at minimum two phrases.  In the UI, I can now add translations, view translations, edit translations, but not delete them (the functionality exists but just not in UI yet).  If deleting a _phrase_ causes a translation to contain only one or zero phrases, however, then the translation _is_ automatically deleted cascadingly.  I cannot add existing phrases to a translation yet.  Overall, making progress with basic functionality & plumbing, and almost to the point of the cooler stuff with the learning process.  Nothing is optimized for speed, all for functionality, so that is also probably on the horizon once I'm working with actual larger data sets.  I also anticipate wanting to download a backup of data file.  All in all going well.

2/16/12
Still working through learning process. I have the process itself down,
but I'm trying to get the distributed architecture going.  It's turning
out to be somewhat building my version of a service bus.  I've though about
converting over to NServiceBus from the IEventAggregator in Caliburn,
but that is just too big of a jump for me to handle when I feel the
immediate usefulness of the program is so close.  As far as the coding goes,
at first, I was unknowingly trying to turn everything into pub-sub as far
as the learning process goes, but now I see that you can think of just one of 
the study pieces (the top level study partner) as the one who communicates 
with the viewmodel through pub-sub.  Pub-sub is just one method of getting
the various pieces working in harmony, and it takes a bit more overhead
than just writing a method or even a subclassed implementor, as each step
which would normally be a getter or a method call is now an entire message
which must be accounted for if it gets lost.  Speaking of which, I'm 
developing this as a fire-and-forget model, assuming loss, using an 
"expiration date" as my eventual timeout mechanism...working in the dairy
department 3 years make expiration date very well known to me LOL.  Still
the process is a long one, but I think this is the final major milestone
before I can start using this program for personal use. 

02/29/12
Well, almost have it freaking working.  It's been very slow going, trying to get it together all of the features I've had to forego for getting it done in a reasonable timeframe.  I almost have it usable for myself as far as persisting some kind of knowledge about phrases, and interpreting this persistence. It looks like for right now, it will be storing a timestamp, a string, and a double for the extent of "knowledge" or "belief". Anything can use this PhraseBeliefEdit class, even if they don't use it for phrases I suppose.  Though, I would like in future versions to have a more generic belief class/belief structure that will work more easily with multiple neural networks.  Had some interesting thoughts about those, in terms of aggregating functional neural networks.  Still working through that though, thinking of what precisely each step of "training" a neural network means in terms of an infinitely recursive neural network and a broader meta-neural network.  But I don't care much for expounding further until I can focus on just that aspect of the program, other than to say that training is a resource allocation investment strategy; a resource for which every generation of neural networks (in something similar to the rtNeat algorithm) is competing.  This may be our "fundamental" unit of currency, or at least one implementation of a fundamental resource currency.  Other than that, it's just plodding ahead with this simpler stuff, though the learning process itself is shaping out to be pretty cool, and I believe will be massively effective in and of itself.  The idea is that each MLT (multi-line text) and line phrase will be analogous to the "item" concept in SuperMemo, in that the point is to be reviewing this whole compound entities.  That much was already known.  Now, when you forget something, it will essentially fracture the compound phrase into smaller pieces, each of which will become atomic until the larger MLT/line is "remembered"/"known".  There are other dynamics as well, such as somewhat ignoring the known/forgotten pattern of words when you are first learning them, and not jumping the gun in trying to establish these items' learning parameters.  This is akin to ignoring the spike in information when plugging in a sound jack, or any state transition, which indeed, learning a new item can be considered a state transition, and the spike is the resources in attaining equilibrium for those items' strength in the brain's environment.  That's enough for technical details anyway, I'm just glad to be "back" to coding.  I had to do a lot of white-boarding and thinking and other seemingly "non-work" things that didn't seem to be producing much.  I think I'm on the right track now though.